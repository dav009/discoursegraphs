{
 "metadata": {
  "name": "",
  "signature": "sha256:7650924bd2c266bbee70a0902e6089bf22528861c91604f1e09dccd8e635ae1a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import re\n",
      "from itertools import chain\n",
      "\n",
      "from discoursegraphs.util import ensure_unicode\n",
      "from discoursegraphs.io.tiger import TigerDocumentGraph\n",
      "from discoursegraphs.io.anaphoricity import AnaphoraDocumentGraph\n",
      "\n",
      "DOC_ID_REGEX = '\\d+'\n",
      "\n",
      "TIGER_DIR = os.path.expanduser('~/repos/pcc-annis-merged/maz176/syntax')\n",
      "DAS_DIR = os.path.expanduser('~/repos/pcc-annis-merged/maz176/anaphora/tosik/das')\n",
      "ES_DIR = os.path.expanduser('~/repos/pcc-annis-merged/maz176/anaphora/tosik/es')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tiger_files = !ls $TIGER_DIR/*.xml\n",
      "das_files = !ls $DAS_DIR/*.txt\n",
      "es_files = !ls $ES_DIR/*.txt\n",
      "\n",
      "def get_doc_id(annotation_file_path):\n",
      "    \"\"\"\n",
      "    extracts the numerical document ID from the file name of an annotation file.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    annotation_file_path : str\n",
      "        absolute or relative path to an annotation file\n",
      "        \n",
      "    Returns\n",
      "    -------\n",
      "    doc_id : str\n",
      "        the numerical document ID of the annotation file, e.g. '00001' or '14881'\n",
      "    \"\"\"\n",
      "    file_name = os.path.basename(annotation_file_path)\n",
      "    return re.search(DOC_ID_REGEX, file_name).group()\n",
      "\n",
      "def doc_id2tiger_filename(doc_id, tiger_dir):\n",
      "    \"\"\"\n",
      "    converts a numerical document ID into a Tiger file name (as it is used in PCC).\n",
      "    \"\"\"\n",
      "    return os.path.join(tiger_dir, 'syntax.maz-{}.xml'.format(doc_id))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For each anaphoricity file, there's one Tiger file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all([os.path.isfile(doc_id2tiger_filename(doc_id, TIGER_DIR)) \n",
      "         for doc_id in (get_doc_id(fpath)\n",
      "            for fpath in tiger_files)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ANAPHORICITY_TEST_FILE = os.path.expanduser('~/repos/pcc-annis-merged/maz176/anaphora/tosik/das/maz-10207.anaphora.das.txt')\n",
      "TIGER_TEST_FILE = doc_id2tiger_filename(get_doc_id(ANAPHORICITY_TEST_FILE), TIGER_DIR)\n",
      "\n",
      "adg = AnaphoraDocumentGraph(ANAPHORICITY_TEST_FILE)\n",
      "tdg = TigerDocumentGraph(TIGER_TEST_FILE)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# We need to ensure unicode in anaphoricity.py"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for das_file in das_files:\n",
      "    adg = AnaphoraDocumentGraph(das_file)\n",
      "    tiger_file = doc_id2tiger_filename(get_doc_id(das_file), TIGER_DIR)\n",
      "    tdg = TigerDocumentGraph(tiger_file)\n",
      "\n",
      "    all_token_node_ids = list(chain.from_iterable((tdg.node[root_id]['tokens']\n",
      "                                              for root_id in tdg.sentences)))\n",
      "    \n",
      "    for i, node_id in enumerate(adg.nodes_iter()):\n",
      "        if 'anaphoricity:token' in adg.node[node_id]['layers']:\n",
      "            anaphora_token = adg.node[node_id]['token']\n",
      "            tiger_token = tdg.node[all_token_node_ids[i]]['word']\n",
      "            if ensure_unicode(anaphora_token) != tiger_token:\n",
      "                print das_file\n",
      "                print \"tokens don't match: (anaphoricity) vs. (tiger)\"\n",
      "                print \"\\t\", anaphora_token, tiger_token\n",
      "                break\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/arne/repos/pcc-annis-merged/maz176/anaphora/tosik/das/maz-13125.anaphora.das.txt\n",
        "tokens don't match: (anaphoricity) vs. (tiger)\n",
        "\tund was\n"
       ]
      },
      {
       "ename": "IndexError",
       "evalue": "list index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-7-00ab8eb9cde8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'anaphoricity:token'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0madg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layers'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0manaphora_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'token'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mtiger_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtdg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mall_token_node_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mensure_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manaphora_token\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtiger_token\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[1;32mprint\u001b[0m \u001b[0mdas_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIndexError\u001b[0m: list index out of range"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# different number of tokens ???"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}