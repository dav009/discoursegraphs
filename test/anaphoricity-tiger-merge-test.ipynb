{
 "metadata": {
  "name": "",
  "signature": "sha256:ea3e81e5494a00cebc6d1d615842b775f2ac11bb951de8c93bd18e1789123879"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import re\n",
      "from itertools import chain\n",
      "\n",
      "from discoursegraphs.util import ensure_unicode\n",
      "from discoursegraphs.io.tiger import TigerDocumentGraph\n",
      "from discoursegraphs.io.anaphoricity import AnaphoraDocumentGraph\n",
      "\n",
      "DOC_ID_REGEX = '\\d+'\n",
      "\n",
      "PRIMARY_TEXT_DIR = os.path.expanduser('~/repos/pcc-annis-merged/maz176/primary-data')\n",
      "TOKENIZED_TEXT_DIR = os.path.expanduser('~/repos/pcc-annis-merged/maz176/tokenized')\n",
      "TIGER_DIR = os.path.expanduser('~/repos/pcc-annis-merged/maz176/syntax')\n",
      "DAS_DIR = os.path.expanduser('~/repos/pcc-annis-merged/maz176/anaphora/tosik/das')\n",
      "ES_DIR = os.path.expanduser('~/repos/pcc-annis-merged/maz176/anaphora/tosik/es')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tiger_files = !ls $TIGER_DIR/*.xml\n",
      "das_files = !ls $DAS_DIR/*.txt\n",
      "es_files = !ls $ES_DIR/*.txt\n",
      "\n",
      "def get_doc_id(annotation_file_path):\n",
      "    \"\"\"\n",
      "    extracts the numerical document ID from the file name of an annotation file.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    annotation_file_path : str\n",
      "        absolute or relative path to an annotation file\n",
      "        \n",
      "    Returns\n",
      "    -------\n",
      "    doc_id : str\n",
      "        the numerical document ID of the annotation file, e.g. '00001' or '14881'\n",
      "    \"\"\"\n",
      "    file_name = os.path.basename(annotation_file_path)\n",
      "    return re.search(DOC_ID_REGEX, file_name).group()\n",
      "\n",
      "def doc_id2tiger_filename(doc_id, tiger_dir):\n",
      "    \"\"\"\n",
      "    converts a numerical document ID into a Tiger file path (as it is used in PCC).\n",
      "    \"\"\"\n",
      "    return os.path.join(tiger_dir, 'syntax.maz-{}.xml'.format(doc_id))\n",
      "\n",
      "def doc_id2primarytext_filename(doc_id, primary_text_dir):\n",
      "    \"\"\"\n",
      "    converts a numerical document ID into a primary text file path (as it is used in PCC).    \n",
      "    \"\"\"\n",
      "    return os.path.join(primary_text_dir, 'maz-{}.txt'.format(doc_id))\n",
      "                        \n",
      "def doc_id2tokenization_filename(doc_id, tokenized_text_dir):\n",
      "    \"\"\"\n",
      "    converts a numerical document ID into a tokenized text file path (as it is used in PCC).    \n",
      "    \"\"\"\n",
      "    return os.path.join(tokenized_text_dir, 'maz-{}.tok.txt'.format(doc_id))\n",
      "\n",
      "def doc_id2anaphoricity_filename(doc_id, anaphoricity_dir, annotated_word):\n",
      "    \"\"\"\n",
      "    converts a numerical document ID into an anaphora annotation file path (as it is used in PCC).\n",
      "    \"\"\"\n",
      "    assert annotated_word in ('das', 'es')\n",
      "    return os.path.join(anaphoricity_dir, 'maz-{0}.anaphora.{1}.txt'.format(doc_id, annotated_word))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For each anaphoricity file, there's one Tiger file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all([os.path.isfile(doc_id2tiger_filename(doc_id, TIGER_DIR)) \n",
      "         for doc_id in (get_doc_id(fpath)\n",
      "            for fpath in tiger_files)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ANAPHORICITY_TEST_FILE = os.path.expanduser('~/repos/pcc-annis-merged/maz176/anaphora/tosik/das/maz-10207.anaphora.das.txt')\n",
      "TIGER_TEST_FILE = doc_id2tiger_filename(get_doc_id(ANAPHORICITY_TEST_FILE), TIGER_DIR)\n",
      "\n",
      "adg = AnaphoraDocumentGraph(ANAPHORICITY_TEST_FILE)\n",
      "tdg = TigerDocumentGraph(TIGER_TEST_FILE)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# We need to ensure unicode in anaphoricity.py\n",
      "\n",
      "# we need to match the TigerXML tokenization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_anaphoricity_token_ids(anaphora_docgraph):\n",
      "    \"\"\"returns a list of token nodes from an AnaphoraDocumentGraph\"\"\"\n",
      "    token_ids = []\n",
      "    for node_id in anaphora_docgraph.nodes_iter():\n",
      "        if 'anaphoricity:token' in anaphora_docgraph.node[node_id]['layers']:\n",
      "            token_ids.append(node_id)\n",
      "    return token_ids\n",
      "\n",
      "def get_anaphoricity_token(anaphora_docgraph, anaphoricity_token_id):\n",
      "    \"\"\"\n",
      "    returns the unicode token string of an 'anaphoricity' token\n",
      "    \"\"\"\n",
      "    from discoursegraphs.util import ensure_unicode\n",
      "    return ensure_unicode(anaphora_docgraph.node[anaphoricity_token_id]['token'])\n",
      "\n",
      "def get_tiger_token_ids(tiger_docgraph):\n",
      "    \"\"\"returns a list of token nodes from an TigerDocumentGraph\"\"\"\n",
      "    from itertools import chain\n",
      "    return list(chain.from_iterable((tiger_docgraph.node[root_id]['tokens'] \n",
      "                                     for root_id in tiger_docgraph.sentences)))\n",
      "\n",
      "def get_tiger_token(tiger_docgraph, tiger_token_id):\n",
      "    \"\"\"\n",
      "    returns the unicode token string of a tiger token    \n",
      "    \"\"\"\n",
      "    return tiger_docgraph.node[tiger_token_id]['word']\n",
      "\n",
      "\n",
      "for das_file in das_files:\n",
      "    adg = AnaphoraDocumentGraph(das_file)\n",
      "    tiger_file = doc_id2tiger_filename(get_doc_id(das_file), TIGER_DIR)\n",
      "    tdg = TigerDocumentGraph(tiger_file)\n",
      "\n",
      "    adg_token_ids = get_anaphoricity_token_ids(adg)\n",
      "    tdg_token_ids = get_tiger_token_ids(tdg)\n",
      "  \n",
      "#     if len(adg_token_ids) != len(adg_token_ids):\n",
      "#         print das_file\n",
      "#         print len(adg_token_ids), len(adg_token_ids)\n",
      "\n",
      "    for i, node_id in enumerate(adg_token_ids):\n",
      "        anaphora_token = get_anaphoricity_token(adg, node_id)\n",
      "        try:\n",
      "            tiger_token = get_tiger_token(tdg, tdg_token_ids[i])\n",
      "        except IndexError as e:\n",
      "            print das_file\n",
      "            print \"tdg_token_ids has no element w/ number {0}\\n\".format(i)\n",
      "#             pass\n",
      "            \n",
      "        if anaphora_token != tiger_token:\n",
      "            print \" geany\", das_file, doc_id2anaphoricity_filename(get_doc_id(das_file), ES_DIR, 'es'), \\\n",
      "                tiger_file, \\\n",
      "                doc_id2primarytext_filename(get_doc_id(das_file), PRIMARY_TEXT_DIR), \\\n",
      "                doc_id2tokenization_filename(get_doc_id(das_file), TOKENIZED_TEXT_DIR)\n",
      "            print u\"tokens don't match: {0} (anaphoricity) vs. {1} (tiger)\".format(anaphora_token, tiger_token)\n",
      "            try:\n",
      "                print \"index: {0}, node_id: {1}\".format(i, node_id)\n",
      "                print u\"\\tanaphoricity context: {0} {1} __{2}__ {3}\\n\".format(get_anaphoricity_token(adg, adg_token_ids[i-2]), \n",
      "                                                           get_anaphoricity_token(adg, adg_token_ids[i-1]),\n",
      "                                                           get_anaphoricity_token(adg, adg_token_ids[i]),\n",
      "                                                           get_anaphoricity_token(adg, adg_token_ids[i+1]))\n",
      "                print u\"\\ttiger context: {0} {1} __{2}__ {3}\\n\".format(get_tiger_token(tdg, tdg_token_ids[i-2]),\n",
      "                                                                   get_tiger_token(tdg, tdg_token_ids[i-1]),\n",
      "                                                                   get_tiger_token(tdg, tdg_token_ids[i]),\n",
      "                                                                   get_tiger_token(tdg, tdg_token_ids[i+1]))\n",
      "            except:\n",
      "                print \"\\n\"\n",
      "            break\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  geany /home/arne/repos/pcc-annis-merged/maz176/anaphora/tosik/das/maz-3415.anaphora.das.txt /home/arne/repos/pcc-annis-merged/maz176/anaphora/tosik/es/maz-3415.anaphora.es.txt /home/arne/repos/pcc-annis-merged/maz176/syntax/syntax.maz-3415.xml /home/arne/repos/pcc-annis-merged/maz176/primary-data/maz-3415.txt /home/arne/repos/pcc-annis-merged/maz176/tokenized/maz-3415.tok.txt\n",
        "tokens don't match: und (anaphoricity) vs. Austausch (tiger)\n",
        "index: 248, node_id: 249\n",
        "\tanaphoricity context: zwischen wirtschaftlichem __und__ damit\n",
        "\n",
        "\ttiger context: zwischen wirtschaftlichem __Austausch__ und\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fail_adg = AnaphoraDocumentGraph('/home/arne/repos/pcc-annis-merged/maz176/anaphora/tosik/das/maz-3415.anaphora.das.txt')\n",
      "\n",
      "print len(fail_adg.nodes())\n",
      "for node in fail_adg.nodes():\n",
      "    print node, type(node)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "307\n",
        "0 <type 'int'>\n",
        "1 <type 'int'>\n",
        "2 <type 'int'>\n",
        "3 <type 'int'>\n",
        "4 <type 'int'>\n",
        "5 <type 'int'>\n",
        "6 <type 'int'>\n",
        "7 <type 'int'>\n",
        "8 <type 'int'>\n",
        "9 <type 'int'>\n",
        "10 <type 'int'>\n",
        "11 <type 'int'>\n",
        "12 <type 'int'>\n",
        "13 <type 'int'>\n",
        "14 <type 'int'>\n",
        "15 <type 'int'>\n",
        "16 <type 'int'>\n",
        "17 <type 'int'>\n",
        "18 <type 'int'>\n",
        "19 <type 'int'>\n",
        "20 <type 'int'>\n",
        "21 <type 'int'>\n",
        "22 <type 'int'>\n",
        "23 <type 'int'>\n",
        "24 <type 'int'>\n",
        "25 <type 'int'>\n",
        "26 <type 'int'>\n",
        "27 <type 'int'>\n",
        "28 <type 'int'>\n",
        "29 <type 'int'>\n",
        "30 <type 'int'>\n",
        "31 <type 'int'>\n",
        "32 <type 'int'>\n",
        "33 <type 'int'>\n",
        "34 <type 'int'>\n",
        "35 <type 'int'>\n",
        "36 <type 'int'>\n",
        "37 <type 'int'>\n",
        "38 <type 'int'>\n",
        "39 <type 'int'>\n",
        "40 <type 'int'>\n",
        "41 <type 'int'>\n",
        "42 <type 'int'>\n",
        "43 <type 'int'>\n",
        "44 <type 'int'>\n",
        "45 <type 'int'>\n",
        "46 <type 'int'>\n",
        "47 <type 'int'>\n",
        "48 <type 'int'>\n",
        "49 <type 'int'>\n",
        "50 <type 'int'>\n",
        "51 <type 'int'>\n",
        "52 <type 'int'>\n",
        "53 <type 'int'>\n",
        "54 <type 'int'>\n",
        "55 <type 'int'>\n",
        "56 <type 'int'>\n",
        "57 <type 'int'>\n",
        "58 <type 'int'>\n",
        "59 <type 'int'>\n",
        "60 <type 'int'>\n",
        "61 <type 'int'>\n",
        "62 <type 'int'>\n",
        "63 <type 'int'>\n",
        "64 <type 'int'>\n",
        "65 <type 'int'>\n",
        "66 <type 'int'>\n",
        "67 <type 'int'>\n",
        "68 <type 'int'>\n",
        "69 <type 'int'>\n",
        "70 <type 'int'>\n",
        "71 <type 'int'>\n",
        "72 <type 'int'>\n",
        "73 <type 'int'>\n",
        "74 <type 'int'>\n",
        "75 <type 'int'>\n",
        "76 <type 'int'>\n",
        "77 <type 'int'>\n",
        "78 <type 'int'>\n",
        "79 <type 'int'>\n",
        "80 <type 'int'>\n",
        "81 <type 'int'>\n",
        "82 <type 'int'>\n",
        "83 <type 'int'>\n",
        "84 <type 'int'>\n",
        "85 <type 'int'>\n",
        "86 <type 'int'>\n",
        "87 <type 'int'>\n",
        "88 <type 'int'>\n",
        "89 <type 'int'>\n",
        "90 <type 'int'>\n",
        "91 <type 'int'>\n",
        "92 <type 'int'>\n",
        "93 <type 'int'>\n",
        "94 <type 'int'>\n",
        "95 <type 'int'>\n",
        "96 <type 'int'>\n",
        "97 <type 'int'>\n",
        "98 <type 'int'>\n",
        "99 <type 'int'>\n",
        "100 <type 'int'>\n",
        "101 <type 'int'>\n",
        "102 <type 'int'>\n",
        "103 <type 'int'>\n",
        "104 <type 'int'>\n",
        "105 <type 'int'>\n",
        "106 <type 'int'>\n",
        "107 <type 'int'>\n",
        "108 <type 'int'>\n",
        "109 <type 'int'>\n",
        "110 <type 'int'>\n",
        "111 <type 'int'>\n",
        "112 <type 'int'>\n",
        "113 <type 'int'>\n",
        "114 <type 'int'>\n",
        "115 <type 'int'>\n",
        "116 <type 'int'>\n",
        "117 <type 'int'>\n",
        "118 <type 'int'>\n",
        "119 <type 'int'>\n",
        "120 <type 'int'>\n",
        "121 <type 'int'>\n",
        "122 <type 'int'>\n",
        "123 <type 'int'>\n",
        "124 <type 'int'>\n",
        "125 <type 'int'>\n",
        "126 <type 'int'>\n",
        "127 <type 'int'>\n",
        "128 <type 'int'>\n",
        "129 <type 'int'>\n",
        "130 <type 'int'>\n",
        "131 <type 'int'>\n",
        "132 <type 'int'>\n",
        "133 <type 'int'>\n",
        "134 <type 'int'>\n",
        "135 <type 'int'>\n",
        "136 <type 'int'>\n",
        "137 <type 'int'>\n",
        "138 <type 'int'>\n",
        "139 <type 'int'>\n",
        "140 <type 'int'>\n",
        "141 <type 'int'>\n",
        "142 <type 'int'>\n",
        "143 <type 'int'>\n",
        "144 <type 'int'>\n",
        "145 <type 'int'>\n",
        "146 <type 'int'>\n",
        "147 <type 'int'>\n",
        "148 <type 'int'>\n",
        "149 <type 'int'>\n",
        "150 <type 'int'>\n",
        "151 <type 'int'>\n",
        "152 <type 'int'>\n",
        "153 <type 'int'>\n",
        "154 <type 'int'>\n",
        "155 <type 'int'>\n",
        "156 <type 'int'>\n",
        "157 <type 'int'>\n",
        "158 <type 'int'>\n",
        "159 <type 'int'>\n",
        "160 <type 'int'>\n",
        "161 <type 'int'>\n",
        "162 <type 'int'>\n",
        "163 <type 'int'>\n",
        "164 <type 'int'>\n",
        "165 <type 'int'>\n",
        "166 <type 'int'>\n",
        "167 <type 'int'>\n",
        "168 <type 'int'>\n",
        "169 <type 'int'>\n",
        "170 <type 'int'>\n",
        "171 <type 'int'>\n",
        "172 <type 'int'>\n",
        "173 <type 'int'>\n",
        "174 <type 'int'>\n",
        "175 <type 'int'>\n",
        "176 <type 'int'>\n",
        "177 <type 'int'>\n",
        "178 <type 'int'>\n",
        "179 <type 'int'>\n",
        "180 <type 'int'>\n",
        "181 <type 'int'>\n",
        "182 <type 'int'>\n",
        "183 <type 'int'>\n",
        "184 <type 'int'>\n",
        "185 <type 'int'>\n",
        "186 <type 'int'>\n",
        "187 <type 'int'>\n",
        "188 <type 'int'>\n",
        "189 <type 'int'>\n",
        "190 <type 'int'>\n",
        "191 <type 'int'>\n",
        "192 <type 'int'>\n",
        "193 <type 'int'>\n",
        "194 <type 'int'>\n",
        "195 <type 'int'>\n",
        "196 <type 'int'>\n",
        "197 <type 'int'>\n",
        "198 <type 'int'>\n",
        "199 <type 'int'>\n",
        "200 <type 'int'>\n",
        "201 <type 'int'>\n",
        "202 <type 'int'>\n",
        "203 <type 'int'>\n",
        "204 <type 'int'>\n",
        "205 <type 'int'>\n",
        "206 <type 'int'>\n",
        "207 <type 'int'>\n",
        "208 <type 'int'>\n",
        "209 <type 'int'>\n",
        "210 <type 'int'>\n",
        "211 <type 'int'>\n",
        "212 <type 'int'>\n",
        "213 <type 'int'>\n",
        "214 <type 'int'>\n",
        "215 <type 'int'>\n",
        "216 <type 'int'>\n",
        "217 <type 'int'>\n",
        "218 <type 'int'>\n",
        "219 <type 'int'>\n",
        "220 <type 'int'>\n",
        "221 <type 'int'>\n",
        "222 <type 'int'>\n",
        "223 <type 'int'>\n",
        "224 <type 'int'>\n",
        "225 <type 'int'>\n",
        "226 <type 'int'>\n",
        "227 <type 'int'>\n",
        "228 <type 'int'>\n",
        "229 <type 'int'>\n",
        "230 <type 'int'>\n",
        "231 <type 'int'>\n",
        "232 <type 'int'>\n",
        "233 <type 'int'>\n",
        "234 <type 'int'>\n",
        "235 <type 'int'>\n",
        "236 <type 'int'>\n",
        "237 <type 'int'>\n",
        "238 <type 'int'>\n",
        "239 <type 'int'>\n",
        "240 <type 'int'>\n",
        "241 <type 'int'>\n",
        "242 <type 'int'>\n",
        "243 <type 'int'>\n",
        "244 <type 'int'>\n",
        "245 <type 'int'>\n",
        "246 <type 'int'>\n",
        "247 <type 'int'>\n",
        "anaphoricity:root_node <type 'str'>\n",
        "249 <type 'int'>\n",
        "250 <type 'int'>\n",
        "251 <type 'int'>\n",
        "252 <type 'int'>\n",
        "253 <type 'int'>\n",
        "254 <type 'int'>\n",
        "255 <type 'int'>\n",
        "256 <type 'int'>\n",
        "257 <type 'int'>\n",
        "258 <type 'int'>\n",
        "259 <type 'int'>\n",
        "260 <type 'int'>\n",
        "261 <type 'int'>\n",
        "262 <type 'int'>\n",
        "263 <type 'int'>\n",
        "264 <type 'int'>\n",
        "265 <type 'int'>\n",
        "266 <type 'int'>\n",
        "267 <type 'int'>\n",
        "268 <type 'int'>\n",
        "269 <type 'int'>\n",
        "270 <type 'int'>\n",
        "271 <type 'int'>\n",
        "272 <type 'int'>\n",
        "273 <type 'int'>\n",
        "274 <type 'int'>\n",
        "275 <type 'int'>\n",
        "276 <type 'int'>\n",
        "277 <type 'int'>\n",
        "278 <type 'int'>\n",
        "279 <type 'int'>\n",
        "280 <type 'int'>\n",
        "281 <type 'int'>\n",
        "282 <type 'int'>\n",
        "283 <type 'int'>\n",
        "284 <type 'int'>\n",
        "285 <type 'int'>\n",
        "286 <type 'int'>\n",
        "287 <type 'int'>\n",
        "288 <type 'int'>\n",
        "289 <type 'int'>\n",
        "290 <type 'int'>\n",
        "291 <type 'int'>\n",
        "292 <type 'int'>\n",
        "293 <type 'int'>\n",
        "294 <type 'int'>\n",
        "295 <type 'int'>\n",
        "296 <type 'int'>\n",
        "297 <type 'int'>\n",
        "298 <type 'int'>\n",
        "299 <type 'int'>\n",
        "300 <type 'int'>\n",
        "301 <type 'int'>\n",
        "302 <type 'int'>\n",
        "303 <type 'int'>\n",
        "304 <type 'int'>\n",
        "305 <type 'int'>\n",
        "248 <type 'int'>\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# different number of tokens ???"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}